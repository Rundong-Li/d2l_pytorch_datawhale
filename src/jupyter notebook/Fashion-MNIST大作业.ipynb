{"cells":[{"metadata":{"cell_type":"code","id":"6AA402BB54644D7DBBF5D4863BBE4DB8","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"import os\nimport sys\nimport time\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms\nfrom torch import optim\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader","execution_count":1},{"metadata":{"id":"51C19319938D4B25970269FCE219CA95","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# network\nclass Residual(nn.Module):\n    def __init__(self,in_channel,num_channel,use_conv1x1=False,strides=1):\n        super(Residual,self).__init__()\n        self.relu=nn.ReLU()\n        self.bn1=nn.BatchNorm2d(in_channel,eps=1e-3)\n        self.conv1=nn.Conv2d(in_channels =in_channel,out_channels=num_channel,kernel_size=3,padding=1,stride=strides)\n        self.bn2=nn.BatchNorm2d(num_channel,eps=1e-3)\n        self.conv2=nn.Conv2d(in_channels=num_channel,out_channels=num_channel,kernel_size=3,padding=1)\n        if use_conv1x1:\n            self.conv3=nn.Conv2d(in_channels=in_channel,out_channels=num_channel,kernel_size=1,stride=strides)\n        else:\n            self.conv3=None\n\n    def forward(self, x):\n        y=self.conv1(self.relu(self.bn1(x)))\n        y=self.conv2(self.relu(self.bn2(y)))\n        # print (y.shape)\n        if self.conv3:\n            x=self.conv3(x)\n        # print (x.shape)\n        z=y+x\n        return z\n\n# ResNet block\ndef ResNet_block(in_channels,num_channels,num_residuals,first_block=False):\n    layers=[]\n    for i in range(num_residuals):\n        if i==0 and not first_block:\n            layers+=[Residual(in_channels,num_channels,use_conv1x1=True,strides=2)]\n        elif i>0 and not first_block:\n            layers+=[Residual(num_channels,num_channels)]\n        else:\n            layers += [Residual(in_channels, num_channels)]\n    blk=nn.Sequential(*layers)\n    return blk\n\n\nclass ResNet(nn.Module):\n    def __init__(self,in_channel,num_classes):\n        super(ResNet,self).__init__()\n        self.block1=nn.Sequential(nn.Conv2d(in_channels=in_channel,out_channels=64,kernel_size=7,stride=2,padding=3),\n                                  nn.BatchNorm2d(64),\n                                  nn.ReLU(),\n                                  nn.MaxPool2d(kernel_size=3,stride=2,padding=1))\n        self.block2=nn.Sequential(ResNet_block(64,64,2,True),\n                                  ResNet_block(64,128,2),\n                                  ResNet_block(128,256,2),\n                                  ResNet_block(256,512,2))\n        self.block3=nn.Sequential(nn.AvgPool2d(kernel_size=3))\n        self.Dense=nn.Linear(512,10)\n\n    def forward(self,x):\n        y=self.block1(x)\n        y=self.block2(y)\n        y=self.block3(y)\n        y=y.view(-1,512)\n        y=self.Dense(y)\n        return y","execution_count":2},{"metadata":{"id":"88112CDA726249D08AAEA4DD400E4325","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def load_data_fashion_mnist(batch_size, root='/home/kesci/input/FashionMNIST2065'):\n    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n\n    normalize = transforms.Normalize(mean=[0.286], std=[0.353])\n    train_augs = transforms.Compose([transforms.ToTensor(), normalize])\n    test_augs = transforms.Compose([transforms.ToTensor(), normalize])\n    \n    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=train_augs)\n    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=test_augs)\n    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=0)\n    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=0)\n\n    return train_iter, test_iter","execution_count":3},{"metadata":{"id":"BC03822EBE4E44A787B1F068E9738FAD","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"batch_size = 64  \ntrain_iter, test_iter = load_data_fashion_mnist(batch_size, root='/home/kesci/input/FashionMNIST2065')","execution_count":4},{"metadata":{"id":"DBF293C5355444A883940AC3F03DC83A","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def evaluate_accuracy(data_iter, net, device=None):\n    if device is None and isinstance(net, torch.nn.Module):\n        # 如果没指定device就使用net的device\n        device = list(net.parameters())[0].device\n    net.eval() \n    acc_sum, n = 0.0, 0\n    with torch.no_grad():\n        for X, y in data_iter:\n            acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n            n += y.shape[0]\n    net.train() # 改回训练模式\n    return acc_sum / n","execution_count":5},{"metadata":{"id":"82CEF5813D2448FC867BDE16CEA41482","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def train_model(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n    net = net.to(device)\n    print(\"training on \", device)\n    loss = torch.nn.CrossEntropyLoss()\n    best_test_acc = 0\n    for epoch in range(num_epochs):\n        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n        for X, y in train_iter:\n            X = X.to(device)\n            y = y.to(device)\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            optimizer.zero_grad()\n            l.backward()\n            optimizer.step()\n            train_l_sum += l.cpu().item()\n            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n            n += y.shape[0]\n            batch_count += 1\n        test_acc = evaluate_accuracy(test_iter, net)\n        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))\n        if test_acc > best_test_acc:\n            print('find best! save at ..work/best.pth')\n            best_test_acc = test_acc\n            torch.save(net.state_dict(), '/home/kesci/work/best.pth')","execution_count":6},{"metadata":{"id":"8D76689DD4284C1DBD5776FF14CECB20","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"ResNet(\n  (block1): Sequential(\n    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (block2): Sequential(\n    (0): Sequential(\n      (0): Residual(\n        (relu): ReLU()\n        (bn1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (bn2): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (1): Residual(\n        (relu): ReLU()\n        (bn1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (bn2): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n    )\n    (1): Sequential(\n      (0): Residual(\n        (relu): ReLU()\n        (bn1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (bn2): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n      )\n      (1): Residual(\n        (relu): ReLU()\n        (bn1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (bn2): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n    )\n    (2): Sequential(\n      (0): Residual(\n        (relu): ReLU()\n        (bn1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n      )\n      (1): Residual(\n        (relu): ReLU()\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n    )\n    (3): Sequential(\n      (0): Residual(\n        (relu): ReLU()\n        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (bn2): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n      )\n      (1): Residual(\n        (relu): ReLU()\n        (bn1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (bn2): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n    )\n  )\n  (block3): Sequential(\n    (0): AvgPool2d(kernel_size=3, stride=3, padding=0)\n  )\n  (Dense): Linear(in_features=512, out_features=10, bias=True)\n)\n","name":"stdout"}],"source":"net=ResNet(1,10).cuda()\nprint (net)","execution_count":7},{"metadata":{"id":"01895E6E417E4CC7A07572E5C4470595","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"training on  cuda:0\nepoch 1, loss 0.4046, train acc 0.855, test acc 0.872, time 68.2 sec\nfind best! save at ..work/best.pth\nepoch 2, loss 0.2704, train acc 0.900, test acc 0.890, time 68.2 sec\nfind best! save at ..work/best.pth\nepoch 3, loss 0.2349, train acc 0.911, test acc 0.891, time 68.2 sec\nfind best! save at ..work/best.pth\nepoch 4, loss 0.2068, train acc 0.923, test acc 0.908, time 68.1 sec\nfind best! save at ..work/best.pth\nepoch 5, loss 0.1850, train acc 0.930, test acc 0.901, time 68.2 sec\nepoch 6, loss 0.1699, train acc 0.935, test acc 0.901, time 68.1 sec\nepoch 7, loss 0.1533, train acc 0.941, test acc 0.905, time 68.2 sec\nepoch 8, loss 0.1429, train acc 0.946, test acc 0.903, time 68.1 sec\nepoch 9, loss 0.1309, train acc 0.951, test acc 0.900, time 68.2 sec\nepoch 10, loss 0.1195, train acc 0.955, test acc 0.904, time 68.2 sec\n","name":"stdout"}],"source":"lr, num_epochs = 0.01, 10\noptimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4) \ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ntrain_model(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)","execution_count":8},{"metadata":{"id":"064A61A2EC7348BA8B77974751B42327","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 加载最优模型\nnet.load_state_dict(torch.load('/home/kesci/work/best.pth'))\nnet = net.to(device)","execution_count":9},{"metadata":{"id":"8181F863B87C4658811EA5A629C3C59C","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# inference测试集\nnet.eval() \nid = 0\npreds_list = []\nwith torch.no_grad():\n    for X, y in test_iter:\n        batch_pred = list(net(X.to(device)).argmax(dim=1).cpu().numpy())\n        for y_pred in batch_pred:\n            preds_list.append((id, y_pred))\n            id += 1","execution_count":10},{"metadata":{"id":"79BFD006A610429AA50879202C81E604","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 生成csv文件\nwith open('submission.csv', 'w') as f:\n    f.write('ID,Prediction\\n')\n    for id, pred in preds_list:\n        f.write('{},{}\\n'.format(id, pred))","execution_count":11}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}